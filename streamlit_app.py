import streamlit as st
import pandas as pd
import joblib
import json
import numpy as np
import os
import matplotlib.pyplot as plt 
import seaborn as sns 
from huggingface_hub import hf_hub_download

# --- CONFIGURATION (Assumes Student_Performance.csv is in your repo) ---
DATA_FILE = "Student_Performance.csv"
HF_MODEL_REPO_ID = "Shalan1/student-performance-predictor-models" 
RF_MODEL_FILENAME = "rf_model.joblib"

# Hardcoded metrics from your Colab analysis for display
MODEL_METRICS = {
    "Linear Regression": {"RÂ² Score": 0.9634, "MSE": 1.5471},
    "Random Forest Regressor": {"RÂ² Score": 0.9996, "MSE": 0.0019}
}
# ---------------------

# Set page configuration for a better look
st.set_page_config(
    layout="wide", 
    page_title="Student Performance Predictor & Analysis",
    initial_sidebar_state="expanded"
)

# --- CACHED DATA & ARTIFACT LOADING ---

@st.cache_data
def load_data_and_preprocess(file_path):
    """Loads the dataset and performs outlier removal as done during training."""
    try:
        df_full = pd.read_csv(file_path)
    except FileNotFoundError:
        st.error(f"Data file not found: {file_path}. Please ensure '{DATA_FILE}' is committed to your GitHub repository.")
        st.stop()
        
    # Outlier Removal (as done in your Colab code)
    Q1 = df_full['Performance Index'].quantile(0.25)
    Q3 = df_full['Performance Index'].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    df_clean = df_full[(df_full['Performance Index'] >= lower) & (df_full['Performance Index'] <= upper)].copy()
    
    return df_full, df_clean

@st.cache_resource
def load_models_from_hf():
    """Loads all models and preprocessing artifacts (RF from HF, others locally)."""
    
    with st.spinner(f"Downloading large model {RF_MODEL_FILENAME} from Hugging Face..."):
        model_path = hf_hub_download(repo_id=HF_MODEL_REPO_ID, filename=RF_MODEL_FILENAME)
    st.success("Download complete.")
    
    # Load models
    rf_model_loaded = joblib.load(model_path)
    lr_model_loaded = joblib.load("lr_model.joblib")
    scaler_loaded = joblib.load("scaler.joblib")
    encoder_loaded = joblib.load("encoder.joblib")
    
    with open("feature_cols.json", "r") as f:
        feature_cols_loaded = json.load(f)
        
    return rf_model_loaded, lr_model_loaded, scaler_loaded, encoder_loaded, feature_cols_loaded

# Load everything
df_raw, df_processed = load_data_and_preprocess(DATA_FILE)
try:
    rf_model, lr_model, scaler, encoder, feature_cols = load_models_from_hf() 
    st.sidebar.success("All prediction artifacts loaded successfully.")
except Exception as e:
    st.error(f"Error during model loading: {e}. Check your HF_MODEL_REPO_ID and local files.")
    st.stop()


# --- HELPER FUNCTION (With the previous KeyError Fix) ---
def preprocess(df_in):
    """
    Applies the encoder and scaler objects loaded during training.
    Includes explicit column checks to prevent KeyError.
    """
    df = df_in.copy()
    
    # Check 1: Ensure DataFrame is not empty
    if df.empty:
        st.error("Input data frame is empty.")
        return None
        
    # Check 2: Ensure all required feature columns are present in the input DataFrame
    missing_cols = [col for col in feature_cols if col not in df.columns]
    if missing_cols:
        return None

    # 3. Handle Extracurricular Activities (Label Encoding)
    if 'Extracurricular Activities' in df.columns and not np.issubdtype(df['Extracurricular Activities'].dtype, np.number):
        try:
            df['Extracurricular Activities'] = encoder.transform(df['Extracurricular Activities'])
        except ValueError:
            st.warning("Extracurricular Activities column contains labels not seen during training. Please use 'Yes' or 'No'.")
            return None
    
    # 4. Apply Standard Scaling
    try:
        X_scaled = scaler.transform(df[feature_cols])
        return pd.DataFrame(X_scaled, columns=feature_cols)
    except Exception as e:
        st.error(f"An error occurred during scaling: {e}")
        return None


# --- MAIN LAYOUT ---
st.title("ðŸŽ“ Student Performance Predictor & Comprehensive Analysis")
st.markdown("This dashboard provides an in-depth look at the dataset and predictions generated by two machine learning models.")

# ----------------------------------------------------
# 1. DATA INFORMATION & EXPLORATORY DATA ANALYSIS (EDA)
# ----------------------------------------------------
st.header("1. Data Overview & Analysis")
data_tab, stats_tab, viz_tab, metrics_tab = st.tabs(["Dataset Preview", "Statistical Summary", "Visualizations", "Model Performance"])

with data_tab:
    st.subheader("Raw Dataset Preview")
    st.markdown(f"**Dataset Shape:** `{df_raw.shape[0]} rows, {df_raw.shape[1]} columns`")
    st.dataframe(df_raw.head(), use_container_width=True)
    st.subheader("Data Types & Missing Values")
    col1, col2 = st.columns(2)
    with col1:
        st.text("Data Types:\n" + str(df_raw.dtypes))
    with col2:
        st.text("Missing Values:\n" + str(df_raw.isnull().sum()))
    st.markdown(f"**Outlier Removal:** {df_raw.shape[0] - df_processed.shape[0]} rows ({(df_raw.shape[0] - df_processed.shape[0])/df_raw.shape[0]*100:.2f}%) removed from 'Performance Index' column before training.")

with stats_tab:
    st.subheader("Statistical Summary")
    st.dataframe(df_raw.describe(), use_container_width=True)

with viz_tab:
    st.subheader("Key Data Visualizations")
    col1, col2 = st.columns(2)
    
    # Histogram
    with col1:
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.histplot(df_processed['Performance Index'], kde=True, ax=ax)
        ax.set_title("Histogram - Performance Index (Cleaned)")
        st.pyplot(fig)
        
    # Boxplot
    with col2:
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.boxplot(x=df_processed['Performance Index'], ax=ax)
        ax.set_title("Boxplot - Performance Index (Cleaned)")
        st.pyplot(fig)
        
    # Correlation Heatmap
    st.subheader("Feature Correlation")
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(df_processed.corr(numeric_only=True), annot=True, cmap="coolwarm", ax=ax)
    ax.set_title("Correlation Heatmap")
    st.pyplot(fig)
    st.markdown("The heatmap visually confirms that 'Hours Studied' and 'Sample Question Papers Attempted' are the strongest predictors of the Performance Index.")
    # 

with metrics_tab:
    st.subheader("Trained Model Performance Scores")
    
    st.markdown("These scores were generated using the test set (20% of the data) after the models were trained.")

    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Linear Regression RÂ² Score", f"{MODEL_METRICS['Linear Regression']['RÂ² Score']:.4f}")
        st.metric("Linear Regression MSE", f"{MODEL_METRICS['Linear Regression']['MSE']:.4f}")

    with col2:
        st.metric("Random Forest RÂ² Score", f"{MODEL_METRICS['Random Forest Regressor']['RÂ² Score']:.4f}")
        st.metric("Random Forest MSE", f"{MODEL_METRICS['Random Forest Regressor']['MSE']:.4f}")
        
    st.info("The Random Forest Regressor has a significantly higher RÂ² score and lower MSE, indicating it is the superior model for this prediction task.")


# ----------------------------------------------------
# 2. PREDICTION INPUT (Sidebar)
# ----------------------------------------------------
with st.sidebar:
    st.header("1. Prediction Input")
    st.markdown("Enter the student's metrics below to get a prediction.")

    # Model Selection (NEW)
    selected_model_name = st.radio(
        "Select Model for Prediction",
        ("Random Forest Regressor", "Linear Regression"),
        index=0 # Default to the better RF model
    )
    
    st.markdown("---")
    
    # Inputs
    inputs = {}
    inputs['Hours Studied'] = st.slider("Hours Studied (Weekly)", min_value=0.0, max_value=100.0, value=15.0, step=0.5)
    inputs['Sample Question Papers Attempted'] = st.slider("Sample Papers Attempted", min_value=0, max_value=15, value=3, step=1)
    
    opts = list(encoder.classes_) if hasattr(encoder, 'classes_') else ['No', 'Yes']
    inputs['Extracurricular Activities'] = st.selectbox("Extracurricular Activities", options=opts, index=0 if 'No' in opts else 1)
    
    st.markdown("---")
    
    if st.button("Calculate Prediction", use_container_width=True):
        df_in = pd.DataFrame([inputs])
        Xp = preprocess(df_in)

        if Xp is not None:
            # Determine which model to use
            if selected_model_name == "Random Forest Regressor":
                model_to_use = rf_model
            else:
                model_to_use = lr_model

            prediction = model_to_use.predict(Xp)[0]
            
            st.subheader(f"{selected_model_name} Result:")
            st.metric("Predicted Performance Index", f"{prediction:.2f}")


# ----------------------------------------------------
# 3. BATCH PREDICTION (Main Area)
# ----------------------------------------------------
st.header("2. Batch Prediction: Upload CSV")
st.info(f"Your CSV must contain these columns: {', '.join(feature_cols)}")

uploaded = st.file_uploader("Upload CSV for batch predictions", type="csv")

if uploaded is not None:
    try:
        df = pd.read_csv(uploaded)
    except Exception as e:
        st.error(f"Could not read CSV file: {e}")
        st.stop()
        
    missing = [c for c in feature_cols if c not in df.columns]
    
    if missing:
        st.error(f"Missing essential columns: **{', '.join(missing)}** â€” ensure your CSV contains these columns (names must match exactly).")
    else:
        Xp = preprocess(df)
        
        if Xp is not None:
            # Generate predictions for both models
            df['RF_Prediction'] = rf_model.predict(Xp)
            df['LR_Prediction'] = lr_model.predict(Xp)
            df['Ensemble_Avg'] = df[['RF_Prediction','LR_Prediction']].mean(axis=1)
            
            st.success("Batch predictions complete!")
            
            st.dataframe(df.head(10).style.highlight_max(axis=1, subset=['RF_Prediction', 'LR_Prediction', 'Ensemble_Avg']), use_container_width=True)
            
            csv_data = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "Download Predictions CSV", 
                data=csv_data, 
                file_name="student_predictions.csv", 
                mime="text/csv",
                use_container_width=True
            )
